-- tag note front-end js
-- title Formdata fetch
-- date 2020-08-20
-- source https://stackoverflow.com/questions/4526273/what-does-enctype-multipart-form-data-mean
         https://blog.logrocket.com/comparing-the-stream-api-and-async-generators-in-node-js-v10/
;;
# Formdata fetch

## Body of a post.

Four forms to encode data into the body of a post request.

- `application/x-www-form-urlencoded`
- `multipart/form-data`
- `text/plain`
- `application/json`

If you are using json to send binary files you need to encode it into base64, while form data support `Blob` type, so you can append bianry data directly into it. In browser `FormData` can be helpful to construct a form data. `x-www-form-urlencoded` is the method to encode key value pairs in the url directly, `URLSearchParam` can be used to encode key value pairs into linear text form, so you can append it after the url. Plain text is just plain text. It is not unsuual to see people encode binary into base64 with plain text format.

## preflight request with axios.

Axios try to unify the behavior of requests they send between browser and backend, so if server has some specific CORS setting, your node request will be affected too.

I found node-fetch is much better, I really don't like the way axios wrap the response on top of another layer of `AxiosResponse`, seems pretty unnecessary.

## fetch

fetch is the new api used to replace `XMLHTTPRequest`. It's more avilable than axios, since the browser side already ships it by default.

## Difference between array buffer and blob

#### ArrayBuffer
Literatly a fat poiter to fixed lenght array. It can only be manipulated via a view on top of it (Int8Array). It's mutable data and as it's name implied it can be used for buffer.

#### Blob
Binary representation of a raw immutable data.

So in the browser everything is very clear, if you want buffer you use `ArrayBuffer`, if you want immutable binary representation you use `Blob`. The problem is node doesn't support `Blob`, instead it has it's own `Buffer` type.

## Stream and Generator

In python to work with infinite data the first thing comes in mind is to use a generator. Node support generator now, but there is also this `Stream` that deeply nested with other part of the standard library, especially `fs` and `http`. For instance, you can `fs.createReadStream` to create a stream on reading a file, and `httpServerResponse` to create a stream to response large data.

#### Sync Stream
A possible implementation of a stream
```typescript
import {Readable, Writable} from 'stream';

// pull based reader, it will read whenever content in
// buffer is less than a threshold.
const createCounterReader () => {
    let count = 0;
    return new Readable({
        objectMode: true,
        read() {
            count += 1;
            this.push(count);
        }
    })
}

//
const logWriter = new Writable({
    objectMode: true,
    write: (chunk, _, done) => {
        console.log('writing: ', chunk);
        done();
    }
})

// pipe streams
createCounterReader().pipe(logWriter);
// this will count number infinitely.
```

Readable stream will read multiple items at once to fill it's item, and wait for items to be consumed. Once the buffer is filled the reader will not read anymore. It will then wait for the item to be used by some other streams until buffer is below some threashold.

#### Sync Generator
```typescript
function* counter() {
    let counter = 0;
    while (true) {
        count += 1;
        yield count;
    }
}
for (const item of count()) { console.log(item); }
```

## npm link and dependency

You can put the dependency in the package.json while still using `npm link` linked package. All you need to do is to run `npm link <package>` again after you do `npm install`, `npm link` will overwrite the downloaded version with the linked version.

One catch is to remember update the local package version eachtime you publish the package. It's better to write a script for doing that.

## async catch.
Two catches that might block.
#### Unrelated asynchronous operations
```typescript
const p1 = () => new Promise(resolve => {
    setTimeout(() => resolve(1), 2000);
    })
const p2 = () => new Promise(resolve => {
    setTimeout(() => resolve(1), 2000);
    })

// normal
(() => {
    p1.then(a => { console.log(a) });
    p2.then(a => { console.local(a) });
})()

// double the time
(async () => {
    const a = await p1(); console.log(a);
    const b = await p2(); console.log(b);
})
```

Think await as `>>=` that blocks (in a async context), so anything after await get executed sequentially. To achieve the same result as the first example, we want to do someting like `[p1, p2] >>= ...`, to achieve this use `Promise.all()`.

```typescript
(async() => { await Promise.all([p1, p2])})
```

This time it doesn't block.


#### Series of calls await for an asynchrnous operation
Await in for loop get things block.
```typescript
(async () => {
    const as = await somePromise();
    for (a of as) {
        const p = await anotherPromise(a);
        do stuff...
    }
})()
```
The loop is strictly synchronous and you get zero benefits out of async. The solution is still Promise.all.

```typescript
(async () => {
    const promises = (await somePromise()).map(async a => {
        return (await anotherPromise(a));
    });
    const result = await Promise.all(promises);
    do stuff ...
})
```
This doesn't block.


