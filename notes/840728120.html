<h1>Audit this website on chrome.</h1>
<p>I feel my artile load time is pretty laggy, so I tried to play with chrome audit tools to see what's wrong. I feel this is a valuable perf experience and worth note down.</p>
<p>All perf stuffs are better done in incognito mode, otherwise the result will be strongly affected by the plugin you're using. It's also very hard to pick the perf data for your website and the perf data for the plugin, which make perf unnecessarily harder.</p>
<h2>Tools</h2>
<h4>Chrome Performance</h4>
<p>It's the basic perf tool come with chrom for years. Record action for a period of time, and generate a flame chart based on the report from the browser and v8. You can assess what took the largest chunk of times to load. Common time consumer are script and layout.</p>
<h4>React profile</h4>
<p>React has it's specific perf tool, instead of giving a generic perf data from engines, it tells you how much time an individual component takes. This is especially helpful for pin down the spot in react app.</p>
<h4>Audit</h4>
<p>Google lighthouse tool, It gives some heuristic based website quality check of the overall performance of the website, and the report generated includes some advice you can follow along. Advices are in form of <code>don't put too many data in on transfer</code>, it's pretty straight forward.</p>
<h2>What I did</h2>
<p>The perf tool told me the loading time for list page is very high, it's because previously the artile list is sorted forevery single route. I changed that, and thing runs a bit faster.</p>
<p>But the real problem of feeling laggy is because the</p>
<h4>True  lazyness</h4>
<p>My <code>markdowndb.macro</code> macro tries to build a interface that can query static file in a lazy fasion. The initial load will only load headers of the file, and the content will be loaded whenever a <code>get</code> method is called on the interface. But after testing it is not really lazily evaluated, all html files are downloaded right in front of of the load.</p>
<p>My &quot;thunk&quot; is just <code>() -&gt; fetcht(url)</code>, and whenever the app calls <code>get</code>, it will invoke the functinon.</p>
<h4>Layout problem</h4>
<h2>What I learnt</h2>
<h4>RAIL</h4>
<p>User cenetric performance model. Bascially a bunch of heuristics that helps you to talk about the performance.</p>
<p>In large,there're four main aspects to assess. namely <code>Response</code>, <code>Animation</code>, <code>Idle</code>, <code>Load</code>. Based on the types of app, the performance goals can shift.</p>
<p>Some metrics (tolerances)</p>
<pre><code>0 - 16 ms         smooth animatino (60 fps)
0 - 100 ms        response to user action.
100 - 1000ms      loading page or changing view
1000ms or more    beyond this point ppl lose focus
10000ms or more   ppl tend to abandon the task
</code></pre>
<h4>Cache static resource with HTTP caching</h4>
<p>Cache TTL can be set from the server HTTP response header. Like <code>Cache-Control: max-age=300000</code>. How long to set is totally depends on the data type. If it's immutable data, then it's ok to set to a long time. For volatile data it might have a shorter cache TTL or <code>no-chace</code>.</p>
<h4>Avoid chaining critical requests</h4>
<p>If too many requests jammed at the same time, the performance of course will be affected. But sometimes it's necessary to have that many requests to make the app work. If it's not possible to optimize the data itself, a way to make things better is to make the app process more lengthy, so it can have more opportunity to fetch data in between. Loading critical data at the beginning of the app also helps avoid jamming.</p>
<h4></h4>
<h2>Conclusion</h2>
<p>A perf really give a lot of insights of the program. It helps you find problem that you might never notice by just looking at the code.</p>
